{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05ee7bf7",
   "metadata": {},
   "source": [
    "# <center> Génération Procédurale de Contenu dans le métavers. \n",
    "    \n",
    "Nous allons utiliser un réseau génératif antagoniste (GAN) pour générer des images procédurales réalistes. Voici une approche plus détaillée et un exemple de code Python pour illustrer cela :\n",
    "\n",
    "- Étape 1 : Préparation des données\n",
    "Pour entraîner le GAN, vous aurez besoin d'un ensemble de données d'images réalistes. Vous pouvez utiliser des ensembles de données publics, tels que le dataset CelebA ou CIFAR-10, ou collecter vos propres données d'images réalistes. Assurez-vous d'avoir un ensemble de données d'images réalistes pour l'entraînement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20185db",
   "metadata": {},
   "source": [
    "- Étape 2 : Construction du GAN\n",
    "Le GAN est composé de deux parties principales : le générateur et le discriminateur.\n",
    "\n",
    "Le générateur prend un vecteur latent aléatoire en entrée et génère une image simulée. Il apprend à générer des images réalistes en cherchant à tromper le discriminateur.\n",
    "\n",
    "Le discriminateur prend une image réelle ou générée en entrée et estime la probabilité que l'image soit réelle (1) ou générée (0). Il apprend à distinguer les images réelles des images générées par le générateur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5517a94",
   "metadata": {},
   "source": [
    "### <center> Exemple de code Python pour construire un GAN avec Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a7e63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Reshape, Conv2DTranspose, LeakyReLU, Conv2D, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Définition de la taille du vecteur latent\n",
    "latent_dim = 100\n",
    "\n",
    "# Générateur\n",
    "generator = Sequential()\n",
    "generator.add(Dense(7*7*128, input_dim=latent_dim))\n",
    "generator.add(Reshape((7, 7, 128)))\n",
    "generator.add(Conv2DTranspose(64, kernel_size=4, strides=2, padding='same'))\n",
    "generator.add(Conv2DTranspose(1, kernel_size=4, strides=2, padding='same', activation='sigmoid'))\n",
    "\n",
    "# Discriminateur\n",
    "discriminator = Sequential()\n",
    "discriminator.add(Conv2D(64, kernel_size=4, strides=2, padding='same', input_shape=(28, 28, 1)))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Conv2D(128, kernel_size=4, strides=2, padding='same'))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compilation du discriminateur\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5), metrics=['accuracy'])\n",
    "\n",
    "# GAN\n",
    "gan = Sequential()\n",
    "gan.add(generator)\n",
    "gan.add(discriminator)\n",
    "\n",
    "# Compilation du GAN\n",
    "gan.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002, beta_1=0.5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41470708",
   "metadata": {},
   "source": [
    "- Étape 3 : Entraînement du GAN\n",
    "L'entraînement du GAN se déroule en alternant les étapes suivantes :\n",
    "\n",
    "Échantillonnez un ensemble de vecteurs latents aléatoires.\n",
    "Utilisez le générateur pour générer des images simulées à partir de ces vecteurs latents.\n",
    "Mélangez l'ensemble de données réelles avec les images simulées.\n",
    "Entraînez le discriminateur en lui fournissant cet ensemble de données mélangé avec les étiquettes réelles (1 pour les images réelles, 0 pour les images simulées).\n",
    "Échantillonnez à nouveau un ensemble de vecteurs latents aléatoires.\n",
    "Utilisez le GAN pour générer des images simulées à partir de ces vecteurs latents.\n",
    "Entraînez le GAN en lui fournissant ces images simulées avec des étiquettes réelles (1). Notez que le discriminateur est gelé pendant cette étape pour que seul le générateur soit mis à jour.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d75c92",
   "metadata": {},
   "source": [
    "## <center> Entraînement du GAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfcae40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boucle d'entraînement\n",
    "epochs = 10000\n",
    "batch_size = 128\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Échantillonnage des vecteurs latents aléatoires\n",
    "    random_latent_vectors = tf.random.normal(shape=(batch_size, latent_dim))\n",
    "\n",
    "    # Génération d'images simulées\n",
    "    generated_images = generator.predict(random_latent_vectors)\n",
    "\n",
    "    # Échantillonnage d'images réelles\n",
    "    real_images = # Charger un batch d'images réelles depuis l'ensemble de données\n",
    "\n",
    "    # Création de l'ensemble de données mélangé\n",
    "    combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "    labels = tf.concat([tf.zeros((batch_size, 1)), tf.ones((batch_size, 1))], axis=0)\n",
    "\n",
    "    # Entraînement du discriminateur\n",
    "    discriminator_loss = discriminator.train_on_batch(combined_images, labels)\n",
    "\n",
    "    # Échantillonnage de nouveaux vecteurs latents aléatoires\n",
    "    random_latent_vectors = tf.random.normal(shape=(batch_size, latent_dim))\n",
    "\n",
    "    # Création d'étiquettes réelles pour le GAN\n",
    "    misleading_targets = tf.ones((batch_size, 1))\n",
    "\n",
    "    # Geler le discriminateur pendant l'entraînement du GAN\n",
    "    discriminator.trainable = False\n",
    "\n",
    "    # Entraînement du GAN\n",
    "    gan_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
    "\n",
    "    # Affichage des pertes d'entraînement\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch: {epoch}, Discriminator Loss: {discriminator_loss[0]}, GAN Loss: {gan_loss}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d307db",
   "metadata": {},
   "source": [
    "Cette boucle d'entraînement itère sur les époques et effectue les étapes d'entraînement décrites ci-dessus.\n",
    "\n",
    "Après l'entraînement, vous pouvez utiliser le générateur pour créer des images procédurales réalistes en échantillonnant des vecteurs latents aléatoires. Par exemple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a2d6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Génération d'une image procédurale\n",
    "random_latent_vector = tf.random.normal(shape=(1, latent_dim))\n",
    "generated_image = generator.predict(random_latent_vector)\n",
    "\n",
    "# Affichage de l'image générée\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25019cb4",
   "metadata": {},
   "source": [
    "Ce code génère une seule image procédurale à partir d'un vecteur latent aléatoire et l'affiche."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
